# 项目结构与进展文档
# TCM Diagnosis System - 中医智能诊疗系统

---

## 📊 项目概览

**项目目标**: 微调Qwen2.5-7B中医模型，并对比CoT prompting的效果提升

**核心实验设计**:
- 基线: 微调后的Qwen2.5-7B（零样本推理）
- 实验组: 微调后的Qwen2.5-7B + CoT prompting
- 研究问题: CoT能否进一步提升领域微调模型的表现？

**技术栈**:
- 基座模型: Qwen2.5-7B-Instruct
- 微调方法: QLoRA (4-bit)
- 训练框架: LLamaFactory
- 数据集: SylvanL/Traditional-Chinese-Medicine-Dataset-SFT (368万条)

**开发周期**: 5-7天 (DDL: 11月23日)

**总预算**: ¥200-300（仅云GPU训练费用）

---

## ✅ 已完成任务

### Phase 0: 项目初始化 ✅
- [x] 创建项目仓库 (2024-11-17)
- [x] 创建Conda虚拟环境 (2024-11-17)
- [x] 确定最终技术方案: 微调Qwen + CoT对比

### Phase 1: 环境搭建 ✅
- [x] 创建.gitignore文件 (2024-11-17)
- [x] 创建requirements.txt (2024-11-17)
- [x] 安装依赖包 (2024-11-17)
- [x] 验证环境配置 (2024-11-17)

### Phase 2: 数据准备 ✅
- [x] 下载中医SFT数据集 (3,677,727条) (2024-11-18)
- [x] 数据预处理与格式统一 (2024-11-18)
  - 正确处理instruction+input格式
  - 生成full_question字段
- [x] 划分训练/验证/测试集 (2024-11-18)
  - 训练集: 3,493,840 条 (95%)
  - 验证集: 73,554 条 (2%)
  - 测试集: 110,333 条 (3%)
- [x] 准备评测集 (2024-11-18)
  - 快速评测集: 100 条
  - 完整评测集: 500 条
- [x] 数据质量检查 (2024-11-18)
- [x] 创建Prompt构建器 (2024-11-18)
- [x] 创建30%训练子集 (2024-11-18)
  - 训练集: 1,164,613 条 (30%)
  - 用于快速验证训练流程

### Phase 3: Prompt设计 ✅
- [x] 设计零样本Prompt模板 (2024-11-18)
- [x] 设计CoT Prompt模板 (2024-11-18)
- [x] 实现Prompt构建器 (2024-11-18)
- [x] 测试Prompt效果 (2024-11-18)

### Phase 4: 模型训练 ✅
- [x] 创建LLamaFactory配置文件 (dataset_info.json) (2024-11-18)
- [x] 配置训练参数 (2024-11-18)
- [x] 创建训练脚本 (train_LOW_MEM.sh) (2024-11-18)
- [x] 下载Qwen2.5-7B-Instruct基座模型 (2024-11-18)
- [x] **完成QLoRA微调训练** (2024-11-19) 🎉
  - 开始时间: 2024-11-18 22:48
  - 完成时间: 2024-11-19 19:37
  - 训练时长: **20小时45分32秒**
  - 总步数: 18,198 steps
  - 最终Loss: 1.111
  - 训练吞吐: 15.584 samples/s
  - checkpoint已保存至: `./models/checkpoints/qwen2.5-7b-tcm-lora`

---

## ⏳ 进行中任务

### 当前任务更新 (2024-11-19 21:00)
- [x] 模型训练完成 ✅
- [ ] **创建评测脚本** ⏳ 进行中
  - 加载LoRA模型
  - 实现批量推理
  - 支持零样本和CoT两种模式
- [ ] 快速评测（100条）
- [ ] 完整评测（500条）
- [ ] 结果分析和可视化

---

## 📝 待办任务（按优先级排序）

### Phase 5: 模型评测 (11/19-11/20)
- [ ] **创建评测脚本**
  - [ ] 加载训练好的LoRA模型
  - [ ] 实现批量推理功能
  - [ ] 保存预测结果
  
- [ ] **零样本评测**
  - [ ] 在100条快速集上测试
  - [ ] 在500条完整集上评测
  - [ ] 保存预测结果
  - [ ] 计算评测指标
  
- [ ] **CoT评测**
  - [ ] 使用CoT prompt进行推理
  - [ ] 保存推理链和最终结果
  - [ ] 计算评测指标
  - [ ] 分析推理链质量

### Phase 6: 结果分析 (11/20-11/21)
- [ ] **对比分析**
  - [ ] 准确率对比（整体和分类别）
  - [ ] F1/ROUGE对比
  - [ ] 推理时间对比
  - [ ] 可视化对比图表
  
- [ ] **案例分析**
  - [ ] 精选10-20个典型案例
  - [ ] 分析CoT改善的案例
  - [ ] 分析CoT失效的案例
  - [ ] 总结规律
  
- [ ] **错误分析**
  - [ ] 分类错误类型
  - [ ] 统计各类错误占比
  - [ ] 深入分析原因

### Phase 7: 论文撰写 (11/21-11/23)
- [ ] 完成论文框架
- [ ] 撰写各章节
- [ ] 制作表格和图表
- [ ] 添加典型案例
- [ ] 校对和润色
- [ ] 最终检查

---

## 📊 训练结果摘要

### 训练配置
```yaml
数据集: tcm_train_30p (1,164,613条，原数据集30%)
基座模型: Qwen/Qwen2.5-7B-Instruct
微调方法: QLoRA (4-bit量化)

LoRA参数:
  rank: 32  # 降低以节省显存
  alpha: 64
  target_modules: q_proj, v_proj  # 仅2层以节省显存

训练参数:
  per_device_train_batch_size: 2  # 降低以节省显存
  gradient_accumulation_steps: 8  # 增加以保持有效batch_size=64
  learning_rate: 1e-4
  num_train_epochs: 1.0
  max_length: 1024  # 降低以节省显存
  warmup_steps: 100
  lr_scheduler_type: cosine
  save_steps: 1000
  logging_steps: 10
  bf16: true
  gradient_checkpointing: true
  quantization_bit: 4

GPU配置:
  使用GPU: 4,5,6,7 (4张卡)
  每卡显存: 24GB
  分布式训练: DDP
```

### 训练指标
```yaml
总体指标:
  总步数: 18,198 steps
  训练时长: 20小时45分32秒
  最终训练Loss: 1.111
  
性能指标:
  训练样本/秒: 15.584
  训练步数/秒: 0.244
  每步平均耗时: 4.11秒
  
计算量:
  总FLOPs: 8,190,459,563 GF (8.19 TFLOPs)

可训练参数:
  LoRA参数量: 161,480,704 (161.5M)
  占总参数比: 2.08%
  总参数量: 7,777,097,216 (7.78B)
```

### 模型输出
```
保存位置: ./models/checkpoints/qwen2.5-7b-tcm-lora/
包含文件:
  - adapter_config.json (LoRA配置)
  - adapter_model.safetensors (LoRA权重)
  - tokenizer相关文件
  - 训练配置文件
```

---

## 📊 数据统计摘要

### 数据规模
```
原始数据: 3,677,727 条
├─ 训练集(完整): 3,493,840 条 (95%)
├─ 训练集(30%子集): 1,164,613 条 ← 实际使用
├─ 验证集: 73,554 条 (2%)
└─ 测试集: 110,333 条 (3%)

评测集:
├─ 快速评测: 100 条
└─ 完整评测: 500 条
```

### 数据特征
```
input字段统计:
- input为空: ~16% (约60万条)
- input有内容: ~84% (约290万条)

长度统计:
- 平均总长度: 120 字符
- input有内容的样本: 平均133字符
- input为空的样本: 平均50字符
```

---

## 🔧 关键配置信息

### 评测配置（待执行）
```yaml
对比实验:
  实验1 - 零样本 (Baseline):
    模型: 微调后的Qwen2.5-7B + LoRA
    Prompt: 零样本模板
    温度: 0.1
    max_tokens: 2048
    
  实验2 - CoT (实验组):
    模型: 微调后的Qwen2.5-7B + LoRA (相同模型)
    Prompt: CoT模板
    温度: 0.1
    max_tokens: 4096

评测指标:
  - 准确率 (Exact Match)
  - F1分数 (Token-level)
  - ROUGE-L
  - 推理时间
```

### Prompt模板

#### 零样本Prompt
```python
def build_zero_shot_prompt(full_question):
    return f"""你是一位经验丰富的中医医生。请根据以下信息给出诊断和治疗建议。

{full_question}

请给出你的诊断和治疗方案："""
```

#### CoT Prompt
```python
def build_cot_prompt(full_question):
    return f"""你是一位经验丰富的中医医生。请按照中医"辨证论治"的思维方式，逐步分析以下问题。

{full_question}

请按以下步骤思考（每步都要明确写出）：

【步骤1 - 四诊信息总结】
从望、闻、问、切四个方面总结关键信息。

【步骤2 - 病机分析】
分析病因、病位、病性。

【步骤3 - 证型判断】
基于以上分析，判断证型。

【步骤4 - 治法确定】
根据证型确定治疗原则。

【步骤5 - 方药选择】
选择合适的方剂和药物。

请开始分析："""
```

---

## 📈 进度时间线（最新）

| 日期 | 阶段 | 任务 | 状态 |
|------|------|------|------|
| 11/17 | Phase 1 | 环境搭建 | ✅ 完成 |
| 11/18 | Phase 2 | 数据下载 | ✅ 完成 |
| 11/18 | Phase 2 | 数据预处理 | ✅ 完成 |
| 11/18 | Phase 3 | Prompt设计 | ✅ 完成 |
| 11/18 | Phase 4 | 训练配置 | ✅ 完成 |
| 11/18-11/19 | Phase 4 | **模型训练** | ✅ **完成** 🎉 |
| 11/19-11/20 | Phase 5 | 评测准备 | ⏳ 进行中 |
| 11/20 | Phase 5 | 快速评测 | ⏳ 待开始 |
| 11/20-11/21 | Phase 5 | 完整评测 | ⏳ 待开始 |
| 11/21 | Phase 6 | 结果分析 | ⏳ 待开始 |
| 11/21-11/23 | Phase 7 | 论文撰写 | ⏳ 待开始 |

**关键里程碑**:
- ✅ **11/18 今晚**: 完成训练配置
- ✅ **11/18-11/19**: 完成模型训练（用时20.75小时）
- 🎯 **11/19 今晚**: 完成评测准备
- 🎯 **11/20 全天**: 完成所有评测
- 🎯 **11/21 全天**: 完成结果分析
- 🎯 **11/23 中午**: 完成论文

---

## 🎯 实验设计详解

### 研究问题
**核心问题**: CoT prompting能否进一步提升领域微调后模型的性能？

### 实验假设
1. **H1**: 领域微调能显著提升基座模型在中医问答任务上的表现
2. **H2**: CoT prompting能进一步提升微调模型的推理质量
3. **H3**: CoT的提升效果在复杂案例上更明显

### 实验变量
- **自变量**: Prompting方法（零样本 vs CoT）
- **因变量**: 准确率、F1、ROUGE-L、推理时间
- **控制变量**: 相同的微调模型、相同的测试集、相同的生成参数

---

## 💡 重要提醒

### 今天必须完成 (11/19)
1. ✅ 模型训练 - 已完成
2. ⏳ 评测准备 - 进行中
3. ⏳ 快速评测 - 今晚完成

### 成本和时间
```yaml
成本:
  - 云GPU训练: ¥0 (本地4卡训练)
  - 推理成本: ¥0 (本地)
  总计: ¥0 🎉

已用时间:
  - 环境搭建: 1小时 ✅
  - 数据准备: 2小时 ✅
  - Prompt设计: 0.5小时 ✅
  - 训练配置: 0.5小时 ✅
  - 模型训练: 20.75小时 ✅
  
剩余时间:
  - 评测准备: 0.5小时 (今天)
  - 评测执行: 4-6小时 (11/20)
  - 结果分析: 6-8小时 (11/21)
  - 论文撰写: 1.5天 (11/21-23)
```

---

## 📞 下一步行动

### 🔥 立即执行（接下来1小时）

**任务**: 创建评测脚本，开始模型评测

**步骤**:
1. 创建评测脚本 `05_evaluate.py`
2. 加载训练好的LoRA模型
3. 在快速评测集（100条）上测试
4. 对比零样本 vs CoT效果
5. 保存结果并分析

**预期输出**:
- 零样本推理结果 (100条)
- CoT推理结果 (100条)
- 初步性能对比

---

## 🎉 重大进展

### 训练成功！
- ✅ 模型训练完成，耗时20小时45分钟
- ✅ 最终Loss收敛至1.111
- ✅ LoRA权重已保存
- ✅ 所有checkpoint完整

### 技术亮点
1. **显存优化**: 通过降低batch size、sequence length、LoRA rank成功在4×24GB GPU上训练
2. **分布式训练**: DDP 4卡并行，有效batch size=64
3. **训练稳定**: 无NaN、无中断、Loss平稳下降
4. **参数效率**: 仅训练2.08%参数（161M），大幅降低计算成本

### 下一阶段
现在进入评测阶段，验证模型效果并对比CoT提升！

---

**最后更新**: 2024-11-19 19:40  
**当前阶段**: Phase 5 - 模型评测准备  
**实验设计**: 微调Qwen vs 微调Qwen+CoT  
**重大里程碑**: ✅ 模型训练完成！  
**完成进度**: 60% (12/20 主要任务完成) 📈  
**训练状态**: ✅ 成功完成，Loss=1.111  
**下一个目标**: 11/19晚 完成快速评测