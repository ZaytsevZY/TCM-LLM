#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®é¢„å¤„ç†è„šæœ¬ (ä¿®æ­£ç‰ˆ)
åŠŸèƒ½ï¼šæ­£ç¡®å¤„ç†instruction+inputæ ¼å¼ï¼Œåˆ’åˆ†æ•°æ®é›†
"""
import os
import json
import random
from datasets import load_from_disk
from tqdm import tqdm

print("=" * 60)
print("ğŸ”§ ä¸­åŒ»è¯Šç–—ç³»ç»Ÿ - æ•°æ®é¢„å¤„ç† (ä¿®æ­£ç‰ˆ)")
print("=" * 60)

# è®¾ç½®éšæœºç§å­
random.seed(42)

# åˆ›å»ºè¾“å‡ºç›®å½•
os.makedirs("data/processed", exist_ok=True)
os.makedirs("data/evaluation", exist_ok=True)

# ==========================================
# 1. åŠ è½½åŸå§‹æ•°æ®
# ==========================================
print("\n[1/6] ğŸ“‚ åŠ è½½åŸå§‹æ•°æ®...")
try:
    tcm_sft = load_from_disk("data/raw/tcm_sft")
    total_size = len(tcm_sft['train'])
    print(f"âœ“ åŠ è½½æˆåŠŸ: {total_size:,} æ¡æ•°æ®")
except Exception as e:
    print(f"âœ— åŠ è½½å¤±è´¥: {e}")
    exit(1)

# ==========================================
# 2. åˆ†ææ•°æ®æ ¼å¼
# ==========================================
print("\n[2/6] ğŸ” åˆ†ææ•°æ®æ ¼å¼...")

# æ£€æŸ¥å‰100æ¡æ•°æ®
sample_size = min(100, len(tcm_sft['train']))
samples = tcm_sft['train'].select(range(sample_size))

# ç»Ÿè®¡inputå­—æ®µçš„ä½¿ç”¨æƒ…å†µ
empty_input_count = 0
non_empty_input_count = 0
input_lengths = []

for item in samples:
    if not item.get('input', '').strip():
        empty_input_count += 1
    else:
        non_empty_input_count += 1
        input_lengths.append(len(item['input']))

print(f"æ•°æ®æ ¼å¼åˆ†æï¼ˆå‰{sample_size}æ¡ï¼‰:")
print(f"  instructionå­—æ®µ: {sample_size}/{sample_size} æœ‰å†…å®¹")
print(f"  inputå­—æ®µä¸ºç©º: {empty_input_count} æ¡ ({empty_input_count/sample_size*100:.1f}%)")
print(f"  inputå­—æ®µæœ‰å†…å®¹: {non_empty_input_count} æ¡ ({non_empty_input_count/sample_size*100:.1f}%)")
if input_lengths:
    print(f"  inputå¹³å‡é•¿åº¦: {sum(input_lengths)/len(input_lengths):.0f} å­—ç¬¦")

# æ˜¾ç¤ºæ ·ä¾‹
print(f"\næ ·ä¾‹1ï¼ˆinputä¸ºç©ºï¼‰:")
for item in samples:
    if not item.get('input', '').strip():
        print(f"  instruction: {item['instruction'][:80]}...")
        print(f"  input: (ç©º)")
        print(f"  output: {item['output'][:80]}...")
        break

print(f"\næ ·ä¾‹2ï¼ˆinputæœ‰å†…å®¹ï¼‰:")
for item in samples:
    if item.get('input', '').strip():
        print(f"  instruction: {item['instruction'][:80]}...")
        print(f"  input: {item['input'][:80]}...")
        print(f"  output: {item['output'][:80]}...")
        break

# ==========================================
# 3. å®šä¹‰æ•°æ®æ ¼å¼åŒ–å‡½æ•°
# ==========================================
def format_question(item):
    """
    æ ¼å¼åŒ–å®Œæ•´çš„é—®é¢˜
    å¦‚æœinputä¸ºç©ºï¼Œåªç”¨instruction
    å¦‚æœinputä¸ä¸ºç©ºï¼Œç»„åˆinstructionå’Œinput
    """
    instruction = item['instruction'].strip()
    input_text = item.get('input', '').strip()
    
    if input_text:
        # inputæœ‰å†…å®¹ï¼Œç»„åˆä¸¤è€…
        return f"{instruction}\n\nè¡¥å……ä¿¡æ¯ï¼š\n{input_text}"
    else:
        # inputä¸ºç©ºï¼Œåªç”¨instruction
        return instruction

def create_formatted_item(item, index):
    """åˆ›å»ºæ ¼å¼åŒ–åçš„æ•°æ®é¡¹"""
    return {
        "id": index,
        "instruction": item['instruction'],
        "input": item.get('input', ''),
        "output": item['output'],
        "full_question": format_question(item)  # æ–°å¢ï¼šå®Œæ•´é—®é¢˜
    }

# ==========================================
# 4. æ•°æ®åˆ’åˆ†
# ==========================================
print("\n[3/6] âœ‚ï¸  åˆ’åˆ†æ•°æ®é›†...")
print("åˆ’åˆ†æ¯”ä¾‹: è®­ç»ƒé›†95% / éªŒè¯é›†2% / æµ‹è¯•é›†3%")

# å¯é€‰ï¼šå¿«é€Ÿæµ‹è¯•æ¨¡å¼
USE_FULL_DATA = True  # æ”¹ä¸ºFalseä½¿ç”¨10ä¸‡æ¡å¿«é€Ÿæµ‹è¯•
if not USE_FULL_DATA:
    print("âš ï¸  ä½¿ç”¨é‡‡æ ·æ¨¡å¼ï¼ˆ10ä¸‡æ¡ï¼‰ï¼Œé€‚åˆå¿«é€Ÿæµ‹è¯•")
    tcm_sft['train'] = tcm_sft['train'].shuffle(seed=42).select(range(100000))
    total_size = len(tcm_sft['train'])

# ç¬¬ä¸€æ¬¡åˆ’åˆ†ï¼šè®­ç»ƒé›† vs ä¸´æ—¶é›†
train_test_split_ratio = 0.05
print(f"\næ­¥éª¤1: åˆ†ç¦»è®­ç»ƒé›†å’Œä¸´æ—¶é›†...")
split1 = tcm_sft['train'].train_test_split(test_size=train_test_split_ratio, seed=42)
train_dataset = split1['train']
temp_dataset = split1['test']

print(f"  è®­ç»ƒé›†: {len(train_dataset):,} æ¡ (95%)")
print(f"  ä¸´æ—¶é›†: {len(temp_dataset):,} æ¡ (5%)")

# ç¬¬äºŒæ¬¡åˆ’åˆ†ï¼šéªŒè¯é›† vs æµ‹è¯•é›†
print(f"\næ­¥éª¤2: åˆ†ç¦»éªŒè¯é›†å’Œæµ‹è¯•é›†...")
split2 = temp_dataset.train_test_split(test_size=0.6, seed=42)
val_dataset = split2['train']
test_dataset = split2['test']

print(f"  éªŒè¯é›†: {len(val_dataset):,} æ¡ (2%)")
print(f"  æµ‹è¯•é›†: {len(test_dataset):,} æ¡ (3%)")

# ==========================================
# 5. ä¿å­˜å¤„ç†åçš„æ•°æ®
# ==========================================
print("\n[4/6] ğŸ’¾ ä¿å­˜æ•°æ®é›†...")

print("ä¿å­˜è®­ç»ƒé›†...")
train_dataset.save_to_disk("data/processed/train")
print(f"  âœ“ data/processed/train/")

print("ä¿å­˜éªŒè¯é›†...")
val_dataset.save_to_disk("data/processed/val")
print(f"  âœ“ data/processed/val/")

print("ä¿å­˜æµ‹è¯•é›†...")
test_dataset.save_to_disk("data/processed/test")
print(f"  âœ“ data/processed/test/")

# ==========================================
# 6. å‡†å¤‡è¯„æµ‹æ•°æ®é›†ï¼ˆå¸¦å®Œæ•´é—®é¢˜ï¼‰
# ==========================================
print("\n[5/6] ğŸ¯ å‡†å¤‡è¯„æµ‹æ•°æ®é›†...")

# å¿«é€Ÿè¯„æµ‹é›†ï¼š100æ¡
print("åˆ›å»ºå¿«é€Ÿè¯„æµ‹é›†ï¼ˆ100æ¡ï¼‰...")
eval_100 = test_dataset.shuffle(seed=42).select(range(min(100, len(test_dataset))))
eval_100_list = []
for idx, item in enumerate(eval_100):
    formatted_item = create_formatted_item(item, idx)
    eval_100_list.append(formatted_item)

with open("data/evaluation/eval_100.json", "w", encoding="utf-8") as f:
    json.dump(eval_100_list, f, ensure_ascii=False, indent=2)
print(f"  âœ“ data/evaluation/eval_100.json")

# å®Œæ•´è¯„æµ‹é›†ï¼š500æ¡
print("åˆ›å»ºå®Œæ•´è¯„æµ‹é›†ï¼ˆ500æ¡ï¼‰...")
eval_500 = test_dataset.shuffle(seed=42).select(range(min(500, len(test_dataset))))
eval_500_list = []
for idx, item in enumerate(eval_500):
    formatted_item = create_formatted_item(item, idx)
    eval_500_list.append(formatted_item)

with open("data/evaluation/eval_500.json", "w", encoding="utf-8") as f:
    json.dump(eval_500_list, f, ensure_ascii=False, indent=2)
print(f"  âœ“ data/evaluation/eval_500.json")

# ä¿å­˜æ ¼å¼è¯´æ˜æ–‡æ¡£
format_doc = """
# è¯„æµ‹æ•°æ®æ ¼å¼è¯´æ˜

æ¯æ¡æ•°æ®åŒ…å«ä»¥ä¸‹å­—æ®µï¼š

1. id: æ•°æ®ç¼–å·
2. instruction: ä¸»è¦é—®é¢˜/æŒ‡ä»¤
3. input: è¡¥å……ä¿¡æ¯ï¼ˆå¯èƒ½ä¸ºç©ºï¼‰
4. output: æ ‡å‡†ç­”æ¡ˆ
5. full_question: å®Œæ•´é—®é¢˜ï¼ˆinstruction + inputç»„åˆï¼‰

## ä½¿ç”¨æ–¹æ³•

### é›¶æ ·æœ¬æ¨ç†
ä½¿ç”¨ full_question ä½œä¸ºè¾“å…¥ï¼Œç›´æ¥æé—®æ¨¡å‹ã€‚

### CoTæ¨ç†
å°† full_question åµŒå…¥CoT promptæ¨¡æ¿ä¸­ã€‚

## æ³¨æ„äº‹é¡¹

- å¦‚æœinputä¸ºç©ºï¼Œfull_question = instruction
- å¦‚æœinputä¸ä¸ºç©ºï¼Œfull_question = instruction + "\\n\\nè¡¥å……ä¿¡æ¯ï¼š\\n" + input
"""

with open("data/evaluation/FORMAT.md", "w", encoding="utf-8") as f:
    f.write(format_doc)
print(f"  âœ“ data/evaluation/FORMAT.md (æ ¼å¼è¯´æ˜)")

# ==========================================
# 7. æ•°æ®ç»Ÿè®¡
# ==========================================
print("\n[6/6] ğŸ“Š æ•°æ®ç»Ÿè®¡...")

def get_stats(dataset, sample_size=1000):
    """è®¡ç®—æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯"""
    sample_size = min(sample_size, len(dataset))
    sample = dataset.select(range(sample_size))
    
    stats = {
        'empty_input': 0,
        'non_empty_input': 0,
        'output_lengths': [],
        'input_lengths': []
    }
    
    for item in sample:
        input_text = item.get('input', '').strip()
        if not input_text:
            stats['empty_input'] += 1
        else:
            stats['non_empty_input'] += 1
            stats['input_lengths'].append(len(input_text))
        
        stats['output_lengths'].append(len(item['output']))
    
    return stats

train_stats = get_stats(train_dataset)
val_stats = get_stats(val_dataset)
test_stats = get_stats(test_dataset)

print("\ninputå­—æ®µç»Ÿè®¡:")
print(f"  è®­ç»ƒé›†: inputä¸ºç©º={train_stats['empty_input']}, æœ‰å†…å®¹={train_stats['non_empty_input']}")
print(f"  éªŒè¯é›†: inputä¸ºç©º={val_stats['empty_input']}, æœ‰å†…å®¹={val_stats['non_empty_input']}")
print(f"  æµ‹è¯•é›†: inputä¸ºç©º={test_stats['empty_input']}, æœ‰å†…å®¹={test_stats['non_empty_input']}")

print("\noutputé•¿åº¦ç»Ÿè®¡:")
train_avg = sum(train_stats['output_lengths']) / len(train_stats['output_lengths'])
print(f"  è®­ç»ƒé›†: å¹³å‡={train_avg:.0f}, æœ€å°={min(train_stats['output_lengths'])}, æœ€å¤§={max(train_stats['output_lengths'])}")

print("\næ•°æ®é›†è§„æ¨¡:")
print(f"  è®­ç»ƒé›†: {len(train_dataset):,} æ¡ (95%)")
print(f"  éªŒè¯é›†: {len(val_dataset):,} æ¡ (2%)")
print(f"  æµ‹è¯•é›†: {len(test_dataset):,} æ¡ (3%)")
print(f"  å¿«é€Ÿè¯„æµ‹: 100 æ¡")
print(f"  å®Œæ•´è¯„æµ‹: 500 æ¡")

# ==========================================
# å®Œæˆ
# ==========================================
print("\n" + "=" * 60)
print("âœ… æ•°æ®é¢„å¤„ç†å®Œæˆï¼")
print("=" * 60)

print("\nğŸ“ è¾“å‡ºæ–‡ä»¶:")
print("  data/processed/train/          - è®­ç»ƒé›†")
print("  data/processed/val/            - éªŒè¯é›†")
print("  data/processed/test/           - æµ‹è¯•é›†")
print("  data/evaluation/eval_100.json  - å¿«é€Ÿè¯„æµ‹é›†ï¼ˆå¸¦full_questionï¼‰")
print("  data/evaluation/eval_500.json  - å®Œæ•´è¯„æµ‹é›†ï¼ˆå¸¦full_questionï¼‰")
print("  data/evaluation/FORMAT.md      - æ•°æ®æ ¼å¼è¯´æ˜")

print("\nğŸ¯ ä¸‹ä¸€æ­¥:")
print("  1. æ£€æŸ¥æ•°æ®: python scripts/check_data_quality.py")
print("  2. é…ç½®è®­ç»ƒ: ç¼–è¾‘ config/model_config.yaml")
print("  3. å¼€å§‹è®­ç»ƒ: bash scripts/04_train.sh")
